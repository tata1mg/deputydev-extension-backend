from typing import Any, List

from app.common.services.openai.openai_service import OpenAIClient


class LLMClient:
    """
    Client class for interacting with the Language Model (LLM) service.
    """

    def __init__(self, client_type: str = "openai") -> None:
        self.client_type = client_type

    async def get_embeddings(self, input_data: List[Any]) -> List[List[float]]:
        """
        Get embeddings from the Language Model service.

        Args:
            input_data (LLMClientInput): Input data containing batch of text.

        Returns:
            LLMClientOutput: Embeddings generated by the Language Model.
        """
        if self.client_type != "openai":
            raise ValueError("Unsupported client type. Only OpenAI is supported as of now.")

        try:
            embeddings = await OpenAIClient().get_embeddings(input_data)
        except Exception as e:
            raise ValueError(f"Failed to get embeddings: {e}")

        return embeddings

    async def get_client_response(self, conversation_message: list, model: str, response_type: str = "json_object"):
        """
        Makes a call to OpenAI chat completion API with a specific model and conversation messages.
        Implements a retry mechanism in case of a failed request or improper response.

        Args:
            conversation_message: System and user message object.
            model: GPT model to be called.
            confidence_filter_score: Score to filter the comments.
            max_retry: Number of times OpenAI should be called in case of failure or improper response.

        Returns:
           List of filtered comment objects.
        """
        if self.client_type != "openai":
            raise ValueError("Unsupported client type. Only OpenAI is supported as of now.")

        return await OpenAIClient().get_openai_response(conversation_message, model, response_type)
